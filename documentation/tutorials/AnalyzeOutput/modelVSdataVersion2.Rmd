---
title: "Simple Model-Data Comparisons"
author: "Tess McCabe"
date: "4/26/2017"
output: pdf_document
---


In this tutorial we will compare model outputs to data outside of the PEcAn web interface. The goal of this is to demonstrate that it is straightforward to perform additional analyses using PEcAn’s outputs. To do this you can download each of the Output files, and then perform the analyses using whatever software you prefer, or you can perform analyses directly on the PEcAn server itself. Here we’ll be analyzing model outputs in R using a browser-based version of RStudio that’s installed on the server

## Starting RStudio Server

1. Open RStudio Server in a new window at **URL/rstudio** 
 
2.	The username is carya and the password is illinois.

3.	To open a new R script click File > New File > R Script

4.	Use the Files browser on the lower right pane to find where your run(s) are located

  + All PEcAn outputs are stored in the output folder. Click on this to open it up.

  + Within the outputs folder, there will be one folder for each workflow execution. For example, click to open the folder PEcAn_99000000001 if that’s your workflow ID

  + A workflow folder will have a few log and settings files (e.g. pecan.xml) and the following subfolders

```  
run		contains all the inputs for each run
out		contains all the outputs from each run
pft		contains the parameter information for each PFT
```

Within both the run and out folders there will be one folder for each unique model run, where the folder name is the run ID. Click to open the out folder. For our simple case we only did one run so there should be only one folder (e.g. 99000000001). Click to open this folder.

  + Within this folder you will find, among other things, files of the format <year>.nc. Each of these files contains one year of model output in the standard PEcAn netCDF format.

## Load libraries and open connection to the database

```{r}
#Load every Library used
library(PEcAn.all)
library(PEcAn.DB)
require(RPostgreSQL)
library(PEcAn.assim.batch)
library(PEcAn.benchmark)


# Open up a connection to The Bety Database

settings <-list(database = list(bety = list(host = "psql-pecan.bu.edu", driver = "PostgreSQL", user = "bety", dbname = "bety", password = "bety")))
d <- settings$database$bety[c("dbname", "password", "host", "user")]
bety <- src_postgres(host = d$host, user = d$user, password = d$password, dbname = d$dbname)
settings$host$name <- "localhost"
```



## Load model output

```{r}
model_vars<-c("time", "NEE") #varibles being read
model <- as.data.frame(read.output(1000003037, "/fs/data2/output/PEcAn_1000003037/out/1000473575" ,2003,2007,model_vars))
```

The arguments to read.output are the run ID, the folder where the run is located, the start year, the end year, and the variables being read. The README file in the Input file dropdown menue of any sucessful run lists the run ID, the output folder, and the start and end year. 

##	Compare model to flux observations

**First** _load up the observations_ and take a look at the contents of the file

```{r}

File_Path<-"/fs/data3/tmccabe/valicali/AMF_US-Dk3_BASE_HH_3-1.csv"
File_format<-query.format.vars(bety = bety, format.id = 5000000002)
site<-query.site(853,bety$con)

observations<-load_data(data.path = File_Path, format= File_format, time.row = File_format$time.row, site = site) #This will throw an error that not all of the units can be converted. That's ok, as the units of the varibles of interest (NEE) are being converted. 
```

File_Path refers to where you stored your observational data. In this example the defualt file path is an Ameriflux dataset from Duke Forest. 

File_format queries the database for the format your file is in. The defualt format ID "5000000002" is for csv files downloaded from the ameriflux website (aka BADM files).
You could query for diffent kinds of formats that exist in bety or make your own.***LINK TO DOCUMENTATION***

Here 853 is the database site ID for Duke forest, which tells pecan where the data is from and what time zone to assign any time data read in. 

**Third** _align model output and observations_

```{r}
## Standardize time of model output

origin<-"1997-01-01 00:00:00" #Start of the model run.  In YYYY-MM-DD hh:mm:ss format
start_year = year(origin)
end_year = 2007  # End of model run
  
years <- start_year:end_year
seconds <- udunits2::ud.convert(model$time,"years","seconds")
Diff <- diff(model$time)
time_breaks = which(Diff < 0)

if(length(time_breaks) == 0 & length(years)>1){
  model$posix <- as.POSIXct(model$time*86400,origin= origin,tz="UTC")
  model$year <- year(model$posix)
} else {
  N <- c(0,time_breaks, length(model$time))
  n <- diff(N)
  y <- c()
  for (i in seq_along(n)) {
    y <- c(y, rep(years[i], n[i]))
  }
  model$year <- y
  makeDate <- function(x){as.POSIXct(model$time[x]*86400,origin=paste0(model$year[x],"-01-01"),tz="UTC")}
  model$posix <- makeDate(seq_along(model$time))
}

## Align observations and model output

aligned_dat = align_data(model.calc = model, obvs.calc= observations, var =var , start_year =start_year, end_year = end_year, align_method ="mean_over_larger_timestep")

```


**Third**, _convert the model to have the same units as the data_

```{r}
modNEE <- udunits2::ud.convert(out$NEE,"kg m-2 s-1","ug m-2 s-1")/12.0 #12 g C per mol
```

**Fourth**, _plot model predictions vs. observations_ and compare this to a 1:1 line 

```{r}
## match years
obs_time <- lubridate::ymd_hm(obs$TIMESTAMP_START)
sel <- which(lubridate::year(obs_time) == 2004 )

## predicted observed plot
plot(modNEE,obs$NEE_PI[sel])
abline(0,1,col="red")  ## intercept=0, slope=1
```


**Finally**, _plot time-series_ of both the model and data together

```{r}
plot(obs_time[sel],modNEE,type='l',ylab="umol m-2 s-1",xlab="day of year")
lines(obs_time[sel],obs$NEE_PI[sel],col="green")
```
