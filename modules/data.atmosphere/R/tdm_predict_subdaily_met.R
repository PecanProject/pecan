##' Predict Subdaily Meteorology
##' Predict Subdaily Meteorology based off of statistics created in gen.subdaily.models()
# -----------------------------------
# Description
# -----------------------------------
##' @title predict_subdaily_met
##' @family tdm - Temporally Downscale Meteorology
##' @author Christy Rollinson, James Simkins
##' @description This is the main function of the tdm family workflow. This function predicts subdaily meteorology
##'              from daily means using a linear regression modeling approach. It takes a dataset with
##'              daily resolution and temporally downscales it to hourly resolution using the statistics
##'              generated by gen.subdaily.models(). It references the predict.subdaily.function
##'              located in lm_ensemble_sims() which uses a linear regression based approach to downscale.
##'              We generate multiple ensembles of possible hourly values dictated from the models and betas
##'              generated in gen.subdaily.models. Each ensemble member is saved as a netCDF file
##'              in CF conventions and these files are ready to be used in the general PEcAn workflow.
# -----------------------------------
# Parameters
# -----------------------------------
##' @param outfolder - directory where output file will be stored
##' @param in.path - base path to dataset you wish to temporally downscale; Note: in order for parallelization 
##'                  to work, the in.prefix will need to be appended as the final level of the file structure.  
##'                  For example, if prefix is GFDL.CM3.rcp45.r1i1p1, there should be a directory with that title in in.path.
##' @param in.prefix - prefix of model dataset, i.e. if file is GFDL.CM3.rcp45.r1i1p1.2006 the prefix is 'GFDL.CM3.rcp45.r1i1p1'
##' @param path.train - path to CF/PEcAn style training data where each year is in a separate file.
##' @param direction.filter - Whether the model will be filtered backward or forwards in time. options = c("backward", "forwards")
##'                           (default is forward; PalEON will go backward, anybody interested in the future will go forwards)                  
##' @param lm.models.base - path to linear regression model folders generated using gen.subdaily.models
##' @param yrs.predict - years for which you want to generate met.  if NULL, all years in in.path will be done
##' @param ens.labs - vector containing the labels (suffixes) for each ensemble member; this allows you to add to your 
##'                   ensemble rather than overwriting with a default naming scheme
##' @param resids - logical stating whether to pass on residual data or not
##' @param force.sanity - (logical) do we force the data to meet sanity checks?                             
##' @param sanity.tries - how many time should we try to predict a reasonable value before giving up?  We don't want to end up in an infinite loop
##' @param overwrite logical: replace output file if it already exists?
##' @param verbose logical: should \code{\link[ncdf4:ncdf4-package]{ncdf4}} functions print debugging information as they run?
##' @param print.progress - print the progress bar?
##' @param seed - manually set seed for results to be reproducible
##' @export
##' @examples
##' \dontrun{
##' library(PEcAn.data.atmosphere)
##' outfolder = '~/Downscaled_GCM'
##' in.path = '~/raw_GCM'
##' in.prefix = 'GFDL'
##' lm.models.base = 'sf_scratch/US-WCr'
##' dat.train_file = 'Training_data/US-WCr_dat.train.nc'
##' start_date = '2010-01-01'
##' end_date = '2014-12-31'
##' cores.max = 12
##' n.ens = 3}
# -----------------------------------
#----------------------------------------------------------------------
# Begin Script
#----------------------------------------------------------------------

predict_subdaily_met <- function(outfolder, in.path, in.prefix, path.train, direction.filter="forward", lm.models.base,
                                 yrs.predict=NULL, ens.labs = 1:3, resids = FALSE, force.sanity=TRUE, sanity.tries=25,
                                 overwrite = FALSE, verbose = FALSE, seed=format(Sys.time(), "%m%d"), print.progress=FALSE, ...) {
  
  if(direction.filter %in% toupper( c("backward", "backwards"))) direction.filter="backward"
  
  if(!tolower(direction.filter) %in% c("backward", "forward", "backwards", "forwards")) PEcAn.logger::logger.severe("Invalid direction.filter")
  
  vars.hour <- c("air_temperature", "precipitation_flux", "surface_downwelling_shortwave_flux_in_air", 
                 "surface_downwelling_longwave_flux_in_air", "air_pressure", "specific_humidity", 
                 "wind_speed")
  vars.lag <- c("lag.air_temperature", "lag.precipitation_flux", "lag.surface_downwelling_shortwave_flux_in_air", 
                "lag.surface_downwelling_longwave_flux_in_air", "lag.air_pressure", 
                "lag.specific_humidity", "lag.wind_speed")
  
  n.ens <- length(ens.labs)
  
  # Update in.path with our prefix (seems silly, but helps with parallelization)
  in.path <- file.path(in.path, in.prefix)
  
  # Extract the lat/lon info from the first of the source files
  fnow <- dir(in.path, ".nc")[1]
  ncT <- ncdf4::nc_open(file.path(in.path, fnow))
  lat.in <- ncdf4::ncvar_get(ncT, "latitude")
  lon.in <- ncdf4::ncvar_get(ncT, "longitude")
  ncdf4::nc_close(ncT)
  
  # Getting a list of all files/years we want to downscale
  files.tdm <- dir(in.path, ".nc")
  
  yrs.tdm <- strsplit(files.tdm, "[.]")
  yrs.tdm <- matrix(unlist(yrs.tdm), ncol=length(yrs.tdm[[1]]), byrow=T)
  yrs.tdm <- as.numeric(yrs.tdm[,ncol(yrs.tdm)-1]) # Assumes year is always last thing before the file extension
  
  if(!is.null(yrs.predict)){
    files.tdm <- files.tdm[which(yrs.tdm %in% yrs.predict)]
    yrs.tdm <- yrs.tdm[which(yrs.tdm %in% yrs.predict)]
  }
  
  # make sure files and years are ordered in the direction we want to go
  if(direction.filter=="backward"){ 
    yrs.tdm <- yrs.tdm[order(yrs.tdm, decreasing = T)]
    files.tdm <- files.tdm[order(files.tdm, decreasing = T)]
  }

  met.lag <- ifelse(direction.filter=="backward", -1, +1)
  
  # Create wind speed variable if it doesn't exist
  # if (all(is.na(dat.train$wind_speed) == TRUE)) {
      # dat.train$wind_speed <- sqrt(dat.train$eastward_wind^2 + dat.train$northward_wind^2)
  # }


  # Defining variable names, longname & units
  nc.info <- data.frame(CF.name = c("air_temperature", "precipitation_flux",
      "surface_downwelling_shortwave_flux_in_air", "surface_downwelling_longwave_flux_in_air",
      "air_pressure", "specific_humidity", "wind_speed"), longname = c("2 meter mean air temperature",
      "cumulative precipitation (water equivalent)", "incident (downwelling) showtwave radiation",
      "incident (downwelling) longwave radiation", "air_pressureure at the surface",
      "Specific humidity measured at the lowest level of the atmosphere",
      "Wind speed"), units = c("K", "kg m-2 s-1", "W m-2", "W m-2", "Pa",
      "kg kg-1", "m s-1"))
  
  
  # ----------------------------------
  # Prep some info on precipitation distribution
  # ----------------------------------
  # Read in the data and dupe it into the temporal resolution we want to end up with (based on our training data)
  files.train <- dir(path.train, ".nc")
  
  # Getting a list of years just to make things faster for align.met
  yrs.file <- strsplit(files.train, "[.]")
  yrs.file <- matrix(unlist(yrs.file), ncol=length(yrs.file[[1]]), byrow=T)
  yrs.file <- as.numeric(yrs.file[,ncol(yrs.file)-1]) # Assumes year is always last thing before the file extension
  
  train.nl <- yrs.file[which(!lubridate::leap_year(yrs.file))[1]]
  train.leap <- yrs.file[which(lubridate::leap_year(yrs.file))[1]]
  
  # Set up our preciptiation distribution info
  precip.dist <- list()
  precip.dist$hrs.rain <- list()
  precip.dist$hrs.max <- list()
  for(i in 1:366){
    precip.dist$hrs.rain[[i]] <- vector()
    precip.dist$hrs.max[[i]] <- vector()
  }
  for(i in 1:length(files.train)){
    nday <- ifelse(lubridate::leap_year(yrs.file[i]), 366, 365)
    
    ncT <- ncdf4::nc_open(file.path(path.train, files.train[i]))
    precip.hr <- ncdf4::ncvar_get(ncT, "precipitation_flux")
    ncdf4::nc_close(ncT)
    
    obs.day <- round(length(precip.hr)/nday)
    # Setting up precip as a list to make doing
    precip.temp <- list()
    day.ind <- seq(1, length(precip.hr), by=obs.day)
    for(j in seq_along(day.ind)){
      precip.temp[[j]] <- precip.hr[day.ind[j]:(day.ind[j]+23)]
    } # end j loop
    for(j in 1:length(precip.temp)){
      if(j <= 7){
        rain.train <- c(unlist(precip.temp[1:(j+7)]), unlist(precip.temp[(length(precip.temp)-7+j):length(precip.temp)]))
      } else if(j>=(length(precip.temp)-7)){
        rain.train <- c(unlist(precip.temp[j:length(precip.temp)]), unlist(precip.temp[1:(length(precip.temp)-j+6)]))
      } else {
        rain.train <- unlist(precip.temp[(j-7):(j+7)])
      }
      hrs.tmp <- max(round(length(which(rain.train>0))/length(rain.train)*obs.day), 1) # Getting the average number of obs of rain per day
      hrs.tmp <- min(hrs.tmp, obs.day/2) # Just to prevent constant drizzle problem, it's can't rain in more than half the observations
      precip.dist$hrs.rain[[j]] <- c(precip.dist$hrs.rain[[j]], hrs.tmp)
      
      rain.train <- matrix(rain.train, ncol=length(rain.train)/obs.day, byrow = FALSE)
      rain.tot <- apply(rain.train, 1, sum)
      
      precip.dist$hrs.max[[j]] <- c(precip.dist$hrs.max[[j]], which(rain.tot==max(rain.tot))[1])
    }  # end j loop
  } # end file loop
  # ----------------------------------
  
  
  
  # ----------------------------------
  # Set progress bar
  # pb.index <- 1
  if(print.progress==TRUE) pb <- utils::txtProgressBar(min = 0, max = length(yrs.tdm), style = 3)
  # utils::setTxtProgressBar(pb, pb.index)

  for (y in 1:length(yrs.tdm)) {
    yr.train <- ifelse(lubridate::leap_year(yrs.tdm[y]), train.leap, train.nl)
    
    met.out <- align.met(train.path=path.train, source.path=in.path, 
                         yrs.train=yr.train, yrs.source=yrs.tdm[y], 
                         n.ens=1, seed=201708, pair.mems = FALSE)
    
    # Package the raw data into the dataframe that will get passed into the function
    dat.ens <- data.frame(year = met.out$dat.source$time$Year, 
                          doy = met.out$dat.source$time$DOY, 
                          date = met.out$dat.source$time$Date,
                          hour = met.out$dat.source$time$Hour,
                          air_temperature_max.day = met.out$dat.source$air_temperature_maximum, 
                          air_temperature_min.day = met.out$dat.source$air_temperature_minimum,
                          precipitation_flux.day = met.out$dat.source$precipitation_flux, 
                          surface_downwelling_shortwave_flux_in_air.day = met.out$dat.source$surface_downwelling_shortwave_flux_in_air,
                          surface_downwelling_longwave_flux_in_air.day = met.out$dat.source$surface_downwelling_longwave_flux_in_air,
                          air_pressure.day = met.out$dat.source$air_pressure, 
                          specific_humidity.day = met.out$dat.source$specific_humidity,
                          wind_speed.day = met.out$dat.source$wind_speed)
    
    # Create wind speed variable if it doesn't exist
    if(!"wind_speed" %in% names(met.out$dat.source)){
      dat.ens$wind_speed <- sqrt(met.out$dat.source$eastward_wind^2 + met.out$dat.source$northward_wind^2)
    } else {
      dat.ens$wind_speed <- met.out$dat.source$wind_speed
    }
    
    # Set up our simulation time variables; it *should* be okay that this resets each year since it's really only doy that matters
    dat.ens$sim.hr  <- trunc(as.numeric(difftime(dat.ens$date, min(dat.ens$date), tz = "GMT", units = "hour")))+1
    dat.ens$sim.day <- trunc(as.numeric(difftime(dat.ens$date, min(dat.ens$date), tz = "GMT", units = "day")))+1
    # lag.time <- ifelse(direction.filter=="backward", min(dat.train$hour), max(dat.train$hour))
    
    # ------------------------------
    # If this is our first time through, we need to initalize our lags; 
    # we can do so with the data we extracted with met.out
    # ------------------------------
    # Figure out whether we want to use the first or last value to initalize our lags
    # Note: Data should be ordered Jan 1 -> Dec 31; If we're moving backward, we start with 
    #       Dec 31 and we'll want to pull Jan 1.  If we're going forward, we want the opposite
    if(y == 1){
      lag.use <- ifelse(direction.filter=="backward", 1, nrow(met.out$dat.source$time))
      lags.init <- list()
      
      lags.init[["air_temperature"]] <- data.frame(array(mean(met.out$dat.source$air_temperature_maximum[lag.use], met.out$dat.source$air_temperature_minimum[lag.use]), dim=c(1, n.ens)))
      lags.init[["air_temperature_min"]] <- data.frame(array(met.out$dat.source$air_temperature_minimum[lag.use], dim=c(1, n.ens)))
      lags.init[["air_temperature_max"]] <- data.frame(array(met.out$dat.source$air_temperature_minimum[lag.use], dim=c(1, n.ens)))
      for(v in vars.hour[2:length(vars.hour)]){
        lags.init[[v]] <- data.frame(array(met.out$dat.source[[v]][lag.use], dim=c(1,n.ens)))
      }
    }
    # ------------------------------
    
    # ------------------------------
    # Set up the "next" values
    # Unless this is our last year one of the values should be pulled from the next year to process
    # Using align.met because it's making life a bit easier
    # ------------------------------
    # As long as we're not at the end, we can use align.met to pull the appropriate files; temporal resolution doesn't really matter here
    # Note: This gets us everything at the native daily resolution
    if(y < length(yrs.tdm)){
      met.nxt <- align.met(train.path=in.path, source.path=in.path, yrs.train=yrs.tdm[y], yrs.source=yrs.tdm[y+1], n.ens=1, seed=201708, pair.mems = FALSE)
    } else {
      # Yes, this is redundant, but it works and helps keep me sane
      met.nxt <- align.met(train.path=in.path, source.path=in.path, yrs.train=yrs.tdm[y], yrs.source=yrs.tdm[y], n.ens=1, seed=201708, pair.mems = FALSE)
    }
    
    dat.nxt <- data.frame(year = met.nxt$dat.train$time$Year, 
                          doy = met.nxt$dat.train$time$DOY-met.lag, 
                          next.air_temperature_max = met.nxt$dat.train$air_temperature_maximum, 
                          next.air_temperature_min = met.nxt$dat.train$air_temperature_minimum,
                          next.precipitation_flux = met.nxt$dat.train$precipitation_flux, 
                          next.surface_downwelling_shortwave_flux_in_air = met.nxt$dat.train$surface_downwelling_shortwave_flux_in_air,
                          next.surface_downwelling_longwave_flux_in_air = met.nxt$dat.train$surface_downwelling_longwave_flux_in_air,
                          next.air_pressure = met.nxt$dat.train$air_pressure, 
                          next.specific_humidity = met.nxt$dat.train$specific_humidity,
                          next.wind_speed = met.nxt$dat.train$wind_speed)
    
    if(direction.filter=="backward"){
      # If we're filtering backward, and starting with Dec. 31 of yrs.tdm[1] the first "next" is Dec. 30 (doy - 1) 
      # Jan 1 then needs the "next" pulled from the LAST row of yrs.tdm[2] 
      row.last <- nrow(met.nxt$dat.source$time)
      dat.nxt2 <- data.frame(year = met.nxt$dat.train$time$Year[1], 
                             doy = met.nxt$dat.train$time$DOY[1], 
                             next.air_temperature_max = met.nxt$dat.source$air_temperature_maximum[row.last], 
                             next.air_temperature_min = met.nxt$dat.source$air_temperature_minimum[row.last],
                             next.precipitation_flux = met.nxt$dat.source$precipitation_flux[row.last], 
                             next.surface_downwelling_shortwave_flux_in_air = met.nxt$dat.source$surface_downwelling_shortwave_flux_in_air[row.last],
                             next.surface_downwelling_longwave_flux_in_air = met.nxt$dat.source$surface_downwelling_longwave_flux_in_air[row.last],
                             next.air_pressure = met.nxt$dat.source$air_pressure[row.last], 
                             next.specific_humidity = met.nxt$dat.source$specific_humidity[row.last],
                             next.wind_speed = met.nxt$dat.source$wind_speed[row.last])
      dat.nxt <- rbind(dat.nxt2, dat.nxt[1:(nrow(dat.nxt)-1),])
    } else {
      # If we're filtering FORWRDS, and starting with Jan 1 of yrs.tdm[1] the first "next" is Jan 2 (doy + 1) 
      # Dec. 31 then needs the "next" pulled from the FIRST row of yrs.tdm[2] 
      row.last <- nrow(met.nxt$dat.train$time)
      dat.nxt2 <- data.frame(year = met.nxt$dat.train$time$Year[row.last], 
                             doy = met.nxt$dat.train$time$DOY[row.last], 
                             next.air_temperature_max = met.nxt$dat.source$air_temperature_maximum[1], 
                             next.air_temperature_min = met.nxt$dat.source$air_temperature_minimum[1],
                             next.precipitation_flux = met.nxt$dat.source$precipitation_flux[1], 
                             next.surface_downwelling_shortwave_flux_in_air = met.nxt$dat.source$surface_downwelling_shortwave_flux_in_air[1],
                             next.surface_downwelling_longwave_flux_in_air = met.nxt$dat.source$surface_downwelling_longwave_flux_in_air[1],
                             next.air_pressure = met.nxt$dat.source$air_pressure[1], 
                             next.specific_humidity = met.nxt$dat.source$specific_humidity[1],
                             next.wind_speed = met.nxt$dat.source$wind_speed[1])
      dat.nxt <- rbind(dat.nxt[2:nrow(dat.nxt),], dat.nxt2)
    }
    
    # Merging the next into our ensemble data
    dat.ens <- merge(dat.ens, dat.nxt, all.x=T)
    
    dat.ens <- dat.ens[order(dat.ens$date),]
    # ------------------------------
    

    # ----------------------------------- 
    # 2. Predict met vars for each ensemble member 
    # -----------------------------------

    ens.sims <- lm_ensemble_sims(dat.mod = dat.ens, n.ens = n.ens,
                                 path.model = file.path(lm.models.base), lags.list = NULL, 
                                 lags.init = lags.init,
                                 direction.filter=direction.filter,
                                 dat.train = met.out$dat.train, precip.distribution=precip.dist,
                                 force.sanity=force.sanity, sanity.tries=sanity.tries, seed=seed, print.progress=F)
    
    # -----------------------------------

    # -----------------------------------
    # Set up the lags for the next year
    # -----------------------------------
    for(v in names(ens.sims)) {
      lag.use <- ifelse(direction.filter=="backward", 1, nrow(ens.sims[[v]]))
      lags.init[[v]] <- data.frame(ens.sims[[v]][lag.use,])
    }
    # -----------------------------------
    
    # -----------------------------------
    # Save as netcdf file
    # -----------------------------------
    # Set up the time dimension for this year
    hrs.now <- as.numeric(difftime(dat.ens$date, paste0(yrs.tdm[y], "-01-01"),
        tz = "GMT", units = "hour"))

    # Write each year for each ensemble member into its own .nc file
    lat <- ncdf4::ncdim_def(name = "latitude", units = "degree_north",
        vals = lat.in, create_dimvar = TRUE)
    lon <- ncdf4::ncdim_def(name = "longitude", units = "degree_east",
        vals = lon.in, create_dimvar = TRUE)

    ntime <- nrow(dat.ens)
    # diy <- PEcAn.utils::days_in_year(yrs.tdm[y])
    diy <- ifelse(lubridate::leap_year(yrs.tdm[y]), 366, 365)
    days_elapsed <- (seq_len(ntime) * diy / ntime) - (0.5 * diy / ntime)
    time <- ncdf4::ncdim_def(name = "time", units = paste0("days since ",
        yrs.tdm[y], "-01-01T00:00:00Z"), vals = as.array(days_elapsed), create_dimvar = TRUE,
        unlim = TRUE)

    dim <- list(lat, lon, time)

    var.list <- list()
    for (j in seq_along(nc.info$CF.name)) {
      var.list[[j]] <- ncdf4::ncvar_def(name = as.character(nc.info$CF.name[j]),
          units = as.character(nc.info$units[j]), dim = dim, missval = -9999,
          verbose = verbose)
    } # End j loop

    for (i in seq_len(n.ens)) {
        df <- data.frame(matrix(ncol = length(nc.info$name), nrow = nrow(dat.ens)))
        colnames(df) <- nc.info$name
        for (j in nc.info$CF.name) {
            ens.sims[[j]][["X1"]]
            e <- paste0("X", i)
            df[,j] <- ens.sims[[j]][[e]]
        }

        df <- df[, c("air_temperature", "precipitation_flux", "surface_downwelling_shortwave_flux_in_air",
            "surface_downwelling_longwave_flux_in_air", "air_pressure",
            "specific_humidity", "wind_speed")]
        colnames(df) <- nc.info$CF.name

        # Set up the home folder
        out.ens <- file.path(outfolder, paste(in.prefix, ens.labs[i], sep="."))
        dir.create(out.ens, showWarnings = FALSE, recursive = TRUE)
        
        loc.file <- file.path(out.ens, paste(in.prefix, ens.labs[i], stringr::str_pad(yrs.tdm[y], 4, "left", pad="0"), "nc", sep="."))
        loc <- ncdf4::nc_create(filename = loc.file, vars = var.list, verbose = verbose)

        for (j in nc.info$CF.name) {
            ncdf4::ncvar_put(nc = loc, varid = as.character(j), vals = df[[j]][seq_len(nrow(df))])
        }
        ncdf4::nc_close(loc)
    } # End writing ensemble members 
    if(print.progress==TRUE) utils::setTxtProgressBar(pb, y)
    # print(paste0("finished year ", yrs.tdm[y]))
    # -----------------------------------
    
    rm(met.out, dat.ens, met.nxt, dat.nxt, dat.nxt2, ens.sims)
    
  } # End year loop
  msg.done <- paste("Temporal Downscaling Complete:", in.prefix, min(yrs.tdm), "-", max(yrs.tdm), sep=" ")
  return(msg.done)
} # End function
