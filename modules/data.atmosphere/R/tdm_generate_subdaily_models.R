#' Generate Subdaily Models
#'
#' Create statistical models to predict subdaily meteorology
#' This is the 2nd function in the tdm workflow that takes the dat.train_file that is created from the
#'              nc2dat.train function and generates "lag.days" and "next.days". These variables pass along information
#'              of the previous time step and provides a preview of the next time step. After these variables are created,
#'              the models are generated by calling the tdm_temporal_downscale_functions.R scripts and these models
#'              and betas are saved separately. Please note that these models and betas require a significant
#'              amount of space. The storage required varies by the size of the training dataset, but prepare for
#'              >100 GB. These will be called later in tdm_predict_subdaily_met to perform the linear regression
#'              analysis.
#'
#' @family tdm - Temporally Downscale Meteorology
#' @author Christy Rollinson, James Simkins
#'
#' @param outfolder - directory where models will be stored *** storage required varies by size of training dataset, but prepare for >10 GB
#' @param path.train - path to CF/PEcAn style training data where each year is in a separate file.
#' @param yrs.train - which years of the training data should be used for to generate the model for 
#'                    the subdaily cycle.  If NULL, will default to all years
#' @param direction.filter - Whether the model will be filtered backward or forward in time. options = c("backward", "forward")
#'                           (PalEON will go backward, anybody interested in the future will go forward)                  
#' @param in.prefix not used
#' @param n.beta - number of betas to save from linear regression model
#' @param resids - logical stating whether to pass on residual data or not (this increases both memory & storage requirements)
#' @param parallel - logical stating whether to run temporal_downscale_functions.R in parallel 
#' @param n.cores - deals with parallelization
#' @param day.window - integer specifying number of days around the day being modeled you want to use data from for that 
#'                     specific hours coefficients. Must be integer because we want statistics from the same time of day
#'                     for each day surrounding the model day
#' @param seed - seed for randomization to allow for reproducible results                    
#' @param overwrite logical: replace output file if it already exists?
#' @param verbose logical, currently ignored
#' @param print.progress - print progress bar? (gets passed through)
#' @export
#'
gen.subdaily.models <- function(outfolder, path.train, yrs.train, direction.filter="forward", in.prefix,  
    n.beta, day.window, seed=Sys.time(), resids = FALSE, parallel = FALSE, n.cores = NULL, overwrite = TRUE, 
    verbose = FALSE, print.progress=FALSE) {
  
    # pb.index <- 1
    # pb <- utils::txtProgressBar(min = 1, max = 8, style = 3)
    
    # Just in case we have a capitalization or singular/plural issue 
    if(direction.filter %in% toupper( c("backward", "backwards"))) direction.filter="backward"
  
    # ----- 1.0 Read data & Make time stamps ---------- Load the data
    
    vars.info <- data.frame(CF.name = c("air_temperature", "precipitation_flux", "air_temperature_max", 
                                        "air_temperature_min", "surface_downwelling_shortwave_flux_in_air", 
                                        "surface_downwelling_longwave_flux_in_air", "air_pressure", "specific_humidity", 
                                        "eastward_wind", "northward_wind", "wind_speed"))
    
    
    
    # Getting a list of all the available files and then subsetting to just the ones we 
    # actually want to use
    files.train <- dir(path.train, ".nc")
    yrs.file <- strsplit(files.train, "[.]")
    yrs.file <- matrix(unlist(yrs.file), ncol=length(yrs.file[[1]]), byrow=T)
    yrs.file <- as.numeric(yrs.file[,ncol(yrs.file)-1]) # Assumes year is always last thing before the file extension
    
    if(!is.null(yrs.train)){
      files.train <- files.train[which(yrs.file %in% yrs.train)]
      yrs.file <- yrs.file[which(yrs.file %in% yrs.train)]
    }
    
    met.out <- align.met(train.path=path.train, source.path=path.train, 
                         yrs.train=yrs.file, yrs.source=yrs.file[1], 
                         n.ens=1, seed=seed, pair.mems = FALSE)
    
    dat.train <- data.frame(year = met.out$dat.train$time$Year, 
                            doy = met.out$dat.train$time$DOY, 
                            date = met.out$dat.train$time$Date,
                            hour = met.out$dat.train$time$Hour,
                            air_temperature = met.out$dat.train$air_temperature, 
                            precipitation_flux = met.out$dat.train$precipitation_flux, 
                            surface_downwelling_shortwave_flux_in_air = met.out$dat.train$surface_downwelling_shortwave_flux_in_air,
                            surface_downwelling_longwave_flux_in_air = met.out$dat.train$surface_downwelling_longwave_flux_in_air,
                            air_pressure = met.out$dat.train$air_pressure, 
                            specific_humidity = met.out$dat.train$specific_humidity
                            )
    
    if(!"wind_speed" %in% names(met.out$dat.train)){
      dat.train$wind_speed <- sqrt(met.out$dat.train$eastward_wind^2 + met.out$dat.train$northward_wind^2)
    } else {
      dat.train$wind_speed <- met.out$dat.train$wind_speed
    }
    
    # these non-standard variables help us organize our modeling approach
    # Reference everything off of the earliest date; avoiding 0s because that makes life difficult
    dat.train$sim.hr <- trunc(as.numeric(difftime(dat.train$date, min(dat.train$date), tz = "GMT", units = "hour")))+1
    dat.train$sim.day <- trunc(as.numeric(difftime(dat.train$date, min(dat.train$date), tz = "GMT", units = "day")))+1
    # dat.train$time.day2 <- as.integer(dat.train$time.day + 1/(48 * 2)) + 1  # Offset by half a time step to get time stamps to line up
    
    # ----- 1.1 Coming up with the daily means that are what we can
    # use as predictors ----------
    vars.use <- vars.info$CF.name[vars.info$CF.name %in% names(dat.train)]
    
    train.day <- stats::aggregate(dat.train[, c("air_temperature", "precipitation_flux", 
        "surface_downwelling_shortwave_flux_in_air", "surface_downwelling_longwave_flux_in_air", 
        "air_pressure", "specific_humidity", "wind_speed")], by = dat.train[, 
        c("year", "doy")], FUN = mean)
    names(train.day)[3:9] <- c("air_temperature_mean.day", "precipitation_flux.day", 
        "surface_downwelling_shortwave_flux_in_air.day", "surface_downwelling_longwave_flux_in_air.day", 
        "air_pressure.day", "specific_humidity.day", "wind_speed.day")
    train.day$air_temperature_max.day <- stats::aggregate(dat.train[, c("air_temperature")], 
        by = dat.train[, c("year", "doy")], FUN = max)$x
    train.day$air_temperature_min.day <- stats::aggregate(dat.train[, c("air_temperature")], 
        by = dat.train[, c("year", "doy")], FUN = min)$x

    dat.train <- merge(dat.train[, ], train.day, all.x = T, all.y = T)

    # ----- 1.2 Setting up a 1-hour lag -- smooth transitions at
    # midnight NOTE: because we're filtering from the present back through
    # the past, -1 will associate the closest hour that we've already done
    # (midnight) with the day we're currently working on ----------
    vars.hour <- c("air_temperature", "precipitation_flux", "surface_downwelling_shortwave_flux_in_air", 
        "surface_downwelling_longwave_flux_in_air", "air_pressure", "specific_humidity", 
        "wind_speed")
    vars.lag <- c("lag.air_temperature", "lag.precipitation_flux", "lag.surface_downwelling_shortwave_flux_in_air", 
        "lag.surface_downwelling_longwave_flux_in_air", "lag.air_pressure", 
        "lag.specific_humidity", "lag.wind_speed")
    
    # Specifying what hour we want to lag
    # Note: For forward filtering, we want to associate today with tomorrow (+1 day) using the last observation of today
    #       For backward filtering, we want to associate today with yesterday (-1 day) using the first obs of today
    met.lag <- ifelse(direction.filter=="backward", -1, +1)
    lag.time <- ifelse(direction.filter=="backward", min(dat.train$hour), max(dat.train$hour))
    
    lag.day <- dat.train[dat.train$hour == lag.time, c("year", "doy", "sim.day", vars.hour)]
    names(lag.day)[4:ncol(lag.day)] <- vars.lag
    
    lag.day$lag.air_temperature_min <- stats::aggregate(dat.train[, c("air_temperature")], 
        by = dat.train[, c("year", "doy", "sim.day")], FUN = min)[, "x"]  # Add in a lag for the next day's min temp
    lag.day$lag.air_temperature_max <- stats::aggregate(dat.train[, c("air_temperature")], 
        by = dat.train[, c("year", "doy", "sim.day")], FUN = max)[, "x"]  # Add in a lag for the next day's min temp
    lag.day$sim.day <- lag.day$sim.day + met.lag  # 
    
    
    dat.train <- merge(dat.train, lag.day[, c("sim.day", vars.lag, "lag.air_temperature_min", 
        "lag.air_temperature_max")], all.x = T)
    
    # ----- 1.3 Setting up a variable to 'preview' the next day's mean
    # to help get smoother transitions 
    # NOTE: If we're filtering forward in time, -1 will associate tomorrow with our downscaling
    #       for today
    # ----------
    vars.day <- c("air_temperature_mean.day", "air_temperature_max.day", 
        "air_temperature_mean.day", "precipitation_flux.day", "surface_downwelling_shortwave_flux_in_air.day", 
        "surface_downwelling_longwave_flux_in_air.day", "air_pressure.day", 
        "specific_humidity.day", "wind_speed.day")
    vars.next <- c("next.air_temperature_mean", "next.air_temperature_max", 
        "next.air_temperature_min", "next.precipitation_flux", "next.surface_downwelling_shortwave_flux_in_air", 
        "next.surface_downwelling_longwave_flux_in_air", "next.air_pressure", 
        "next.specific_humidity", "next.wind_speed")
    
    next.day <- dat.train[c("year", "doy", "sim.day", vars.day)]
    names(next.day)[4:ncol(next.day)] <- vars.next
    next.day <- stats::aggregate(next.day[, vars.next], by = next.day[, c("year", "doy", "sim.day")], FUN = mean)
    next.day$sim.day <- next.day$sim.day - met.lag
    
    dat.train <- merge(dat.train, next.day[, c("sim.day", vars.next)], all.x = T)
    
    # Order the data just to make life easier
    dat.train <- dat.train[order(dat.train$date),]
    
    # ----- 1.4 calculate air_temperature_min & air_temperature_max as
    # departure from mean; order data ---------- Lookign at max & min as
    # departure from mean
    dat.train$max.dep <- dat.train$air_temperature_max.day - dat.train$air_temperature_mean.day
    dat.train$min.dep <- dat.train$air_temperature_min.day - dat.train$air_temperature_mean.day
    
    # ----- 2.1 Generating all the daily models, save the output as
    # .Rdata files, then clear memory Note: Could save Betas as .nc files
    # that we pull from as needed to save memory; but for now just leaving
    # it in the .Rdata file for eas Note: To avoid propogating too much
    # wonkiness in hourly data, any co-variates are at the daily level
    # Note: If mod.precipitation_flux.doy doesn't run, try increasing the
    # day.window for this variable. The lack of non-zero values makes it
    # difficult for the linear regression model to calculate coefficients
    # sometimes ---------

    temporal.downscale.functions(dat.train = dat.train, n.beta = n.beta, day.window = day.window, 
                                 resids = resids, n.cores = n.cores, 
                                 seed = seed, outfolder = outfolder, print.progress=print.progress) 
}

# Helper function
substrRight <- function(x, n) {
  substr(x, nchar(x) - n + 1, nchar(x))
}
