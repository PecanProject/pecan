## PEcAn Docker Architecture {#pecan-docker}

* [Overview](#pecan-docker-overview)
* [PEcAn's `docker-compose`](#pecan-docker-compose)
* [Top-level structure](#pecan-dc-structure)
* [`traefik`](#pecan-dc-traefik)
* [`portainer`](#pecan-dc-portainer)
* [`minio`](#pecan-dc-minio)
* [`thredds`](#pecan-dc-thredds)
* [`postgres`](#pecan-dc-postgres)
* [`rabbitmq`](#pecan-dc-rabbitmq)
* [`bety`](#pecan-dc-bety)
* [`docs`](#pecan-dc-docs)
* [`web`](#pecan-dc-web)
* [`executor`](#pecan-dc-executor)
* [`monitor`](#pecan-dc-monitor)
* [Model-specific containers](#pecan-dc-models)


### Overview {#pecan-docker-overview}

The PEcAn docker architecture consists of many containers (see figure below) that will communicate with each other. The goal of this architecture is to easily expand the PEcAn system by deploying new model containers and registering them with PEcAn. Once this is done the user can now use these new models in their work. The PEcAn framework will setup the configurations for the models, and send a message to the model containers to start execution. Once the execution is finished the PEcAn framework will continue. This is exactly as if the model is running on a HPC machine. Models can be executed in parallel by launching multiple model containers.

```{r, echo=FALSE,out.height= "50%", out.width="50%", fig.align='center'}
knitr::include_graphics("03_topical_pages/94_docker/pecan-docker.png")
```
As can be seen in the figure the architecture leverages of two standard containers (in orange). The first container is postgresql with postgis ([mdillon/postgis](https://hub.docker.com/r/mdillon/postgis/)) which is used to store the database used by both BETY and PEcAn. The second containers is a messagebus, more specifically RabbitMQ ([rabbitmq](https://hub.docker.com/_/rabbitmq/)). 

The BETY app container  ([pecan/bety](https://hub.docker.com/r/pecan/bety/)) is the front end to the BETY database and is connected to the postgresql container. A http server can be put in front of this container for SSL termination as well to allow for load balancing (by using multiple BETY app containers).

The PEcAn framework containers consist of multiple unique ways to interact with the PEcAn system (none of these containers will have any models installed):

- PEcAn shiny hosts the shiny applications developed and will interact with the database to get all information necessary to display
- PEcAn rstudio is a rstudio environment with the PEcAn libraries preloaded. This allows for prototyping of new algorithms that can be used as part of the PEcAn framework later.
- PEcAn web allows the user to create a new PEcAn workflow. The workflow is stored in the database, and the models are executed by the model containers.
- PEcAn cli will allow the user to give a pecan.xml file that will be executed by the PEcAn framework.  The workflow created from the XML file is stored in the database, and the models are executed by the model containers.

The model containers contain the actual models that are executed as well as small wrappers to make them work in the PEcAn framework. The containers will run the model based on the parameters received from the message bus and convert the outputs back to the standard PEcAn output format. Once the container is finished processing a message it will immediatly get the next message and start processing it.

### PEcAn's `docker-compose` {#pecan-docker-compose}

```{r comment='', echo = FALSE, results = 'hide'}
docker_compose_file <- file.path("..", "docker-compose.yml")
dc_yaml <- yaml::read_yaml(docker_compose_file)
```

The PEcAn Docker architecture is described in full by the PEcAn `docker-compose.yml` file.
For full `docker-compose` syntax, see the [official documentation](https://docs.docker.com/compose/).

This section describes the [top-level structure](#pecan-dc-structure) and each of the services, which are as follows:

- [`traefik`](#pecan-dc-traefik)
- [`portainer`](#pecan-dc-portainer)
- [`minio`](#pecan-dc-minio)
- [`thredds`](#pecan-dc-thredds)
- [`postgres`](#pecan-dc-postgres)
- [`rabbitmq`](#pecan-dc-rabbitmq)
- [`bety`](#pecan-dc-bety)
- [`docs`](#pecan-dc-docs)
- [`web`](#pecan-dc-web)
- [`executor`](#pecan-dc-executor)
- [`monitor`](#pecan-dc-monitor)
- [Model-specific services](#pecan-dc-models)

For reference, the complete `docker-compose` file is as follows:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml, stdout())
```

There are two ways you can override different values in the docker-compose.yml file. The first method is to create a file called `.env` that is placed in the same folder as the docker-compose.yml file. This file can override some of configuration variables used by docker-compose. For example the following is an example of the env file

```{r comment='', echo = FALSE}
docker_env_file <- file.path("..", "docker", "env.example")
writeLines(readLines(docker_env_file))
```

You can also extend the `docker-compose.yml` file with a `docker-compose.override.yml` file (in the same directory), allowing you to add more services, or for example to change where the volumes are stored (see [official documentation](https://docs.docker.com/compose/extends/)). For example the following will change the volume for postgres to be stored in your home directory:

```
version: "3"

volumes:
  postgres:
    driver_opts:
      type: none
      device: ${HOME}/postgres
      o: bind
```

### Top-level structure {#pecan-dc-structure}

The root of the `docker-compose.yml` file contains three sections:

- `services` -- This is a list of services provided by the application, with each service corresponding to a container.
When communicating with each other internally, the hostnames of containers correspond to their names in this section.
For instance, regardless of the "project" name passed to `docker-compose up`, the hostname for connecting to the PostgreSQL database of any given container is _always_ going to be `postgres` (e.g. you should be able to access the PostgreSQL database by calling the following from inside the container: `psql -d bety -U bety -h postgres`).
The services comprising the PEcAn application are described below.

- `networks` -- This is a list of networks used by the application.
Containers can only communicate with each other (via ports and hostnames) if they are on the same Docker network, and containers on different networks can only communicate through ports exposed by the host machine.
We just provide the network name (`pecan`) and resort to Docker's default network configuration.
Note that the services we want connected to this network include a `networks: ... - pecan` tag.
For more details on Docker networks, see the [official documentation](https://docs.docker.com/network/).

- `volumes` -- Similarly to `networks`, this just contains a list of volume names we want.
Briefly, in Docker, volumes are directories containing files that are meant to be shared across containers.
Each volume corresponds to a directory, which can be mounted at a specific location by different containers.
For example, syntax like `volumes: ... - pecan:/data` in a service definition means to mount the `pecan` "volume" (including its contents) in the `/data` directory of that container.
Volumes also allow data to persist on containers between restarts, as normally, any data created by a container during its execution is lost when the container is re-launched.
For example, using a volume for the database allows data to be saved between different runs of the database container.
Without volumes, we would start with a blank database every time we restart the containers. 
For more details on Docker volumes, see the [official documentation](https://docs.docker.com/storage/volumes/).
Here, we define three volumes:

	- `postgres` -- This contains the data files underlying the PEcAn PostgreSQL database (BETY).
	Notice that it is mounted by the `postgres` container to `/var/lib/postgresql/data`.
	This is the data that we pre-populate when we run the Docker commands to [initialize the PEcAn database](#pecan-docker-quickstart-init).
	Note that these are the values stored _directly in the PostgreSQL database_.
	The default files to which the database points (i.e. `dbfiles`) are stored in the `pecan` volume, described below.
	
	- `rabbitmq` -- This volume contains persistent data for RabbitMQ.
	It is only used by the `rabbitmq` service.
	
	- `pecan` -- This volume contains PEcAn's `dbfiles`, which include downloaded and converted model inputs, processed configuration files, and outputs.
	It is used by almost all of the services in the PEcAn stack, and is typically mounted to `/data`.
 
### `traefik` {#pecan-dc-traefik}

[Traefik](https://traefik.io/) manages communication among the different PEcAn services and between PEcAn and the web.
Among other things, `traefik` facilitates the setup of web access to each PEcAn service via common and easy-to-remember URLs.
For instance, the following lines in the `web` service configure access to the PEcAn web interface via the URL http://localhost:8000/pecan/ :

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services$web["labels"], stdout())
```

(Further details in the works...)

The traefik service configuration looks like this:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["traefik"], stdout())
```

 
### `portainer` {#pecan-dc-portainer}

[portainer](https://portainer.io/) is lightweight management UI that allows you to manage the docker host (or swarm). You can use this service to monitor the different containers, see the logfiles, and start and stop containers.

The portainer service configuration looks like this:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["portainer"], stdout())
```

Portainer is accessible by browsing to `localhost:8000/portainer/`. You can either set the password in the `.env` file (for an example see env.example) or you can use the web browser and go to the portainer url. If this is the first time it will ask for your password.

### `minio` {#pecan-dc-minio}

[Minio](https://github.com/minio/minio) is a service that provides access to the a folder on disk through a variety of protocols, including S3 buckets and web-based access.
We mainly use Minio to facilitate access to PEcAn data using a web browser without the need for CLI tools.

Our current configuration is as follows:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["minio"], stdout())
```

The Minio interface is accessible by browsing to `localhost:8000/minio/`.
From there, you can browse directories and download files.
You can also upload files by clicking the red "+" in the bottom-right corner.

Note that it is currently impossible to create or upload directories using the Minio interface (except in the `/data` root directory -- those folders are called "buckets" in Minio).
Therefore, the recommended way to perform any file management tasks other than individual file uploads is through the command line, e.g.

```bash
docker run -it --rm --volumes pecan_pecan:/data --volumes /path/to/local/directory:/localdir ubuntu

# Now, you can move files between `/data` and `/localdir`, create new directories, etc.
```

### `thredds` {#pecan-dc-thredds}

This service allows PEcAn model outputs to be accessible via the [THREDDS data server (TDS)](https://www.unidata.ucar.edu/software/thredds/current/tds/).
When the PEcAn stack is running, the catalog can be explored in a web browser at http://localhost:8000/thredds/catalog.html.
Specific output files can also be accessed from the command line via commands like the following:

```{r, eval = FALSE}
nc <- ncdf4::nc_open("http://localhost:8000/thredds/dodsC/outputs/PEcAn_<workflow_id>/out/<run_id>/<year>.nc")
```

Note that everything after `outputs/` exactly matches the directory structure of the `workflows` directory.

Which files are served, which subsetting services are available, and other aspects of the data server's behavior are configured in the `docker/thredds_catalog.xml` file.
Specifically, this XML tells the data server to use the `datasetScan` tool to serve all files within the `/data/workflows` directory, with the additional `filter` that only files ending in `.nc` are served.
For additional information about the syntax of this file, see the extensive [THREDDS documentation](https://www.unidata.ucar.edu/software/thredds/current/tds/reference/index.html).

Our current configuration is as follows:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["thredds"], stdout())
```


### `postgres` {#pecan-dc-postgres}

This service provides a working PostGIS database.
Our configuration is fairly straightforward:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["postgres"], stdout())
```

Some additional details about our configuration:

- `image` -- This pulls a container with PostgreSQL + PostGIS pre-installed.
Note that by default, we use PostgreSQL version 9.5.
To experiment with other versions, you can change `9.5` accordingly.

- `networks` -- This allows PostgreSQL to communicate with other containers on the `pecan` network.
As mentioned above, the hostname of this service is just its name, i.e. `postgres`, so to connect to the database from inside a running container, use a command like the following: `psql -d bety -U bety -h postgres`

- `volumes` -- Note that the PostgreSQL data files (which store the values in the SQL database) are stored on a _volume_ called `postgres` (which is _not_ the same as the `postgres` _service_, even though they share the same name).

### `rabbitmq` {#pecan-dc-rabbitmq}

[RabbitMQ](https://www.rabbitmq.com/) is a message broker service.
In PEcAn, RabbitMQ functions as a task manager and scheduler, coordinating the execution of different tasks (such as running models and analyzing results) associated with the PEcAn workflow.

Our configuration is as follows:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["rabbitmq"], stdout())
```

Note that the `traefik.frontend.rule` indicates that browsing to http://localhost:8000/rabbitmq/ leads to the RabbitMQ management console.

By default, the RabbitMQ management console has username/password `guest/guest`, which is highly insecure.
For production instances of PEcAn, we highly recommend changing these credentials to something more secure, and removing access to the RabbitMQ management console via Traefik.

### `bety` {#pecan-dc-bety}

This service operates the BETY web interface, which is effectively a web-based front-end to the PostgreSQL database.
Unlike the `postgres` service, which contains all the data needed to run PEcAn models, this service is not essential to the PEcAn workflow.
However, note that certain features of the PEcAn web interface do link to the BETY web interface and will not work if this container is not running.

Our configuration is as follows:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["bety"], stdout())
```

The BETY container Dockerfile is located in the root directory of the [BETY GitHub repository](https://github.com/PecanProject/bety) ([direct link](https://github.com/PecanProject/bety/blob/master/Dockerfile)).

### `docs` {#pecan-dc-docs}

This service will show the documentation for the version of PEcAn running as well as a homepage with links to all relevant endpoints. You can access this at http://localhost:8000/. You can find the documentation for PEcAn at http://localhost:8000/docs/pecan/.

Our current configuration is as follows:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["docs"], stdout())
```

### `web` {#pecan-dc-web}

This service runs the PEcAn web interface.
It is effectively a thin wrapper around a standard Apache web server container from Docker Hub that installs some additional dependencies and copies over the necessary files from the PEcAn source code.

Our configuration is as follows:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["web"], stdout())
```

Its Dockerfile ships with the PEcAn source code, in [`docker/web/Dockerfile`](https://github.com/PecanProject/pecan/blob/develop/docker/web/Dockerfile).

In terms of [actively developing PEcAn using Docker](#pecan-docker-develop), this is the service to modify when making changes to the web interface (i.e. PHP, HTML, and JavaScript code located in the PEcAn `web` directory).

### `executor` {#pecan-dc-executor}

This service is in charge of running the R code underlying the core PEcAn workflow.
However, it is _not_ in charge of executing the models themselves -- model binaries are located on their [own dedicated Docker containers](#pecan-dc-models), and model execution is coordinated by RabbitMQ.

Our configuration is as follows:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["executor"], stdout())
```

Its Dockerfile is ships with the PEcAn source code, in [`docker/executor/Dockerfile`](https://github.com/PecanProject/pecan/blob/develop/docker/executor/Dockerfile).
Its image is built on top of the `pecan/base` image ([`docker/base/Dockerfile`](https://github.com/PecanProject/pecan/blob/develop/docker/base/Dockerfile)), which contains the actual PEcAn source.
To facilitate caching, the `pecan/base` image is itself built on top of the `pecan/depends` image ([`docker/depends/Dockerfile`](https://github.com/PecanProject/pecan/blob/develop/docker/depends/Dockerfile)), a large image that contains an R installation and PEcAn's many system and R package dependencies (which usually take ~30 minutes or longer to install from scratch).

In terms of [actively developing PEcAn using Docker](#pecan-docker-develop), this is the service to modify when making changes to the PEcAn R source code.
Note that, unlike changes to the `web` image's PHP code, changes to the R source code do not immediately propagate to the PEcAn container; instead, you have to re-compile the code by running `make` inside the container.

### `monitor` {#pecan-dc-monitor}

This service will show all models that are currently running http://localhost:8000/monitor/. This list returned is JSON and shows all models (grouped by type and version) that are currently running, or where seen in the past. This list will also contain a list of all current active containers, as well as how many jobs are waiting to be processed.

This service is also responsible for registering any new models with PEcAn so users can select it and execute the model from the web interface.

Our current configuration is as follows:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["monitor"], stdout())
```

### Model-specific containers {#pecan-dc-models}

Additional models are added as additional services.
In general, their configuration should be similar to the following configuration for SIPNET, which ships with PEcAn:

```{r, echo = FALSE, comment = ''}
yaml::write_yaml(dc_yaml$services["sipnet"], stdout())
```

The PEcAn source contains Dockerfiles for ED2 ([`models/ed/Dockerfile`](https://github.com/PecanProject/pecan/blob/develop/models/ed/Dockerfile.)) and SIPNET ([`models/sipnet/Dockerfile`](https://github.com/PecanProject/pecan/blob/develop/models/sipnet/Dockerfile)) that can serve as references.
For additional tips on constructing a Dockerfile for your model, see [Dockerfiles for Models](#model-docker).
